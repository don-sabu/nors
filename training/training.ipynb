{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c1e3130e-6253-43f5-be4b-90685f9841aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c05666d-b90f-401e-bdea-04b9a153cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    " def load_user_data(user_id):\n",
    "    dataset_dir = os.path.join('..','dataset_processing', 'transformed_data', user_id,)\n",
    "    df = pd.read_csv(dataset_dir+\"/train.csv\")\n",
    "    orders = df.iloc[:, 2:].values\n",
    "    return orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a0d2f10-bee4-4f69-89d0-a2a35f0ecbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_output_pairs(user_data, sequence_length):\n",
    "    input_seqs = []\n",
    "    output_seqs = []\n",
    "    for i in range(len(user_data) - sequence_length):\n",
    "        input_seq = np.array(user_data[i:i + sequence_length])\n",
    "        output_seq = np.array(user_data[i + sequence_length])\n",
    "        input_seqs.append(input_seq)\n",
    "        output_seqs.append(output_seq)\n",
    "    return input_seqs, output_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "43784bb4-5b17-4df6-9f72-e231fa3bf4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(input_shape, lstm_units=64, dropout_rate=0.2, num_outputs=1):\n",
    "    # model = tf.keras.Sequential([\n",
    "    #     tf.keras.layers.LSTM(lstm_units, input_shape=input_shape, return_sequences=True),\n",
    "    #     tf.keras.layers.Dropout(dropout_rate),\n",
    "    #     tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_outputs, activation='sigmoid'))\n",
    "    # ])\n",
    "   \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(lstm_units, input_shape=(5, 4615)),\n",
    "        tf.keras.layers.Dense(4615, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75d0faf1-bc8d-41ed-9156-e505d73fd41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, epochs=10, batch_size=32, validation_split=0.2):\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf1c4333-30ef-4ead-b1f6-0fb71ee19146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3b57a74-f302-4dc6-b17e-9c36ecd97c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = os.listdir(os.path.join('..','dataset_processing', 'transformed_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9212db07-e591-49db-bba9-0d45e747ffff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Users: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 831/831 [01:15<00:00, 11.07it/s]\n"
     ]
    }
   ],
   "source": [
    "input_seq = []\n",
    "output_seq = []\n",
    "for user in tqdm(users, desc=\"Processing Users\"):\n",
    "    user_data = load_user_data(f\"{user}\")\n",
    "    input, output = generate_input_output_pairs(user_data, 5)\n",
    "    input_seq += input\n",
    "    output_seq += output\n",
    "input_arr = np.array(input_seq)\n",
    "output_arr = np.array(output_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a9f2fdae-232c-4296-8bb3-bafc639d8121",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(input_arr, output_arr, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6543f3d1-5ad4-4c87-aa48-abce7ffa57ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5c90a1e4-0161-4acb-bc90-b8df29bdeb98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7ad9b7de-0375-4a65-93ae-37ef76199c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_lstm_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d3216fd2-17a6-4b92-a04e-9d9361a557d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.89 GiB for an array with shape (21954, 5, 4615) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[41], line 3\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, X_train, y_train, epochs, batch_size, validation_split)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(model, X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m):\n\u001b[0;32m      2\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.89 GiB for an array with shape (21954, 5, 4615) and data type float32"
     ]
    }
   ],
   "source": [
    "train_model(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9870b79b-e618-4af6-b3c1-7538fe9b55d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1868, 5, 4615)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0f8ad444-1caa-43be-b765-b81646344bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 5, 64)             1198080   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 64)             0         \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 5, 1)             65        \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,198,145\n",
      "Trainable params: 1,198,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "32f66a77-928c-4bc5-993a-d6cffecef84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1868, 4615)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe54ffd0-15dc-4c77-b288-f42c18416e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
